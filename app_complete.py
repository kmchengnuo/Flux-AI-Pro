import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Tuple, Optional
import time
import random
import json
import uuid
import os
import re
from urllib.parse import urlencode, quote
import gc
from streamlit.errors import StreamlitAPIException, StreamlitSecretNotFoundError
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor

# æ‡‰ç”¨é…ç½®
APP_TITLE = "ğŸ¨ AI åœ–åƒç”Ÿæˆå™¨ (å®Œæ•´å¤šæ¨¡å‹ç‰ˆ)"
APP_ICON = "ğŸ¨"
VERSION = "v2.0.0"

# ç‚ºå…è²»æ–¹æ¡ˆè¨­å®šé™åˆ¶
MAX_HISTORY_ITEMS = 25
MAX_FAVORITE_ITEMS = 50
MAX_BATCH_SIZE = 6
REQUEST_TIMEOUT = 180

# æ“´å±•çš„åœ–åƒå°ºå¯¸é è¨­
IMAGE_SIZES = {
    "è‡ªå®šç¾©...": "Custom",
    # æ¨™æº–å°ºå¯¸
    "512x512": "SD æ¨™æº– (1:1)", 
    "768x768": "SD XL æ¨™æº– (1:1)",
    "1024x1024": "æ­£æ–¹å½¢ (1:1)", 
    "1080x1080": "IG è²¼æ–‡ (1:1)",
    # ç¸±å‘
    "512x768": "SD ç¸±å‘ (2:3)",
    "768x1024": "SDXL ç¸±å‘ (3:4)",
    "1080x1350": "IG ç¸±å‘ (4:5)", 
    "1080x1920": "IG Story (9:16)",
    "896x1152": "è‚–åƒæ¨¡å¼ (7:9)",
    # æ©«å‘
    "768x512": "SD æ©«å‘ (3:2)",
    "1024x768": "SDXL æ©«å‘ (4:3)",
    "1200x630": "FB æ©«å‘ (1.91:1)",
    "1536x640": "è¶…å¯¬æ©«å¹… (2.4:1)",
    "1152x896": "é¢¨æ™¯æ¨¡å¼ (9:7)",
    # ç‰¹æ®Šæ ¼å¼
    "640x1536": "è¶…é•·ç¸±å‘ (5:12)",
    "1344x768": "å¯¬å± (16:9)",
    "832x1216": "æ›¸æœ¬é é¢ (13:19)",
}

# å®Œæ•´çš„é¢¨æ ¼é è¨­ç³»çµ±
STYLE_PRESETS = {
    # åŸºç¤é¢¨æ ¼
    "ç„¡": "",
    "é›»å½±æ„Ÿ": "cinematic, dramatic lighting, high detail, sharp focus, epic scene, movie still",
    "å‹•æ¼«é¢¨": "anime, manga style, vibrant colors, clean line art, studio ghibli style, cel shading", 
    "è³½åšé¾å…‹": "cyberpunk, neon lights, futuristic city, high-tech, Blade Runner style, dystopian",
    
    # æ”å½±é¢¨æ ¼
    "äººåƒæ”å½±": "portrait photography, professional headshot, studio lighting, bokeh background, 85mm lens",
    "è¡—é ­æ”å½±": "street photography, candid moment, urban setting, documentary style, natural lighting",
    "é¢¨æ™¯æ”å½±": "landscape photography, golden hour lighting, wide angle view, nature scenery, HDR",
    "å¾®è·æ”å½±": "macro photography, extreme close-up, detailed textures, shallow depth of field",
    "é»‘ç™½æ”å½±": "black and white photography, monochrome, high contrast, dramatic shadows",
    
    # è—è¡“æµæ´¾
    "å°è±¡æ´¾": "impressionism, soft brushstrokes, natural light, Monet style, plein air painting",
    "è¶…ç¾å¯¦ä¸»ç¾©": "surrealism, dreamlike imagery, impossible scenes, Salvador Dali style, melting reality",
    "æ™®æ™®è—è¡“": "pop art, bold colors, comic book style, Andy Warhol aesthetic, screen printing effect",
    "æŠ½è±¡è¡¨ç¾ä¸»ç¾©": "abstract expressionism, emotional brushwork, Jackson Pollock style, paint splatters",
    "ç«‹é«”ä¸»ç¾©": "cubism, geometric shapes, fragmented perspective, Pablo Picasso style, analytical",
    "æ–°è—è¡“é‹å‹•": "art nouveau, ornate decorations, flowing organic lines, Alphonse Mucha style",
    
    # å‚³çµ±è—è¡“
    "æ°´å¢¨ç•«": "traditional Chinese ink painting, brush strokes, minimalist zen aesthetic, black ink on rice paper",
    "æ°´å½©ç•«": "watercolor painting, soft transparent washes, wet-on-wet technique, delicate colors",
    "æ²¹ç•«": "oil painting, thick impasto, rich textures, renaissance style, classical technique",
    "ç´ æ": "pencil sketch, graphite drawing, crosshatching, detailed line work, academic drawing",
    
    # æ•¸ä½è—è¡“
    "3D æ¸²æŸ“": "3D render, octane rendering, photorealistic, volumetric lighting, global illumination",
    "åƒç´ è—è¡“": "pixel art, 8-bit style, retro gaming aesthetic, low resolution, sprite art",
    "ä½é¢å»ºæ¨¡": "low poly art, geometric shapes, minimal vertices, isometric view, faceted surfaces",
    "çŸ¢é‡åœ–": "vector illustration, clean geometric lines, flat design, scalable graphics",
    
    # ç‰¹å®šé¢¨æ ¼
    "è’¸æ±½é¾å…‹": "steampunk aesthetic, Victorian era meets technology, brass gears, copper pipes, clockwork",
    "è³½åšæœ‹å…‹": "cyberpunk style, neon-soaked streets, high-tech low-life, neural implants, megacorp",
    "å¤ªé™½æœ‹å…‹": "solarpunk, ecological futurism, sustainable technology, green architecture, hopeful future",
    "æ³¢æ™®æµªæ½®": "vaporwave aesthetic, 80s nostalgia, neon grids, palm trees, retro futurism",
    
    # å¹»æƒ³é¢¨æ ¼
    "å¥‡å¹»è—è¡“": "fantasy art, magical creatures, epic landscapes, detailed armor, mystical atmosphere",
    "é»‘æš—å¥‡å¹»": "dark fantasy, gothic horror, ominous mood, dramatic shadows, supernatural elements",
    "ç§‘å¹»è—è¡“": "science fiction art, futuristic technology, space scenes, alien worlds, concept art",
    
    # æ¼«ç•«é¢¨æ ¼
    "ç¾å¼æ¼«ç•«": "American comic book style, bold outlines, dynamic poses, superhero aesthetic, halftone dots",
    "æ—¥å¼æ¼«ç•«": "manga style, detailed line art, expressive characters, screen tones, Japanese comics",
    "æ­å¼æ¼«ç•«": "European comic art, detailed backgrounds, realistic proportions, graphic novel style",
    
    # è£é£¾é¢¨æ ¼
    "åŒ…è±ªæ–¯": "Bauhaus design, geometric minimalism, functional aesthetics, primary colors, clean typography",
    "è£é£¾è—è¡“": "art deco style, geometric patterns, luxury aesthetics, gold accents, 1920s glamour",
    "å¾©å¤æµ·å ±": "vintage poster design, retro color palette, bold typography, propaganda style",
    
    # æè³ªé¢¨æ ¼
    "å‰ªç´™è—è¡“": "paper cut art, layered paper sculpture, shadow box effect, handcraft aesthetic",
    "é™¶ç“·é¢¨æ ¼": "ceramic art, glazed pottery, handmade textures, earthy color palette",
    "é‡‘å±¬è³ªæ„Ÿ": "metallic finish, brushed steel, chrome reflection, industrial materials",
    
    # ç‰¹æ®Šæ•ˆæœ
    "éœ“è™¹æ•ˆæœ": "neon lighting effect, glowing edges, electric colors, night club atmosphere",
    "å…‰ç·šè¿½è¹¤": "ray traced lighting, realistic reflections, caustics, global illumination",
    "é›™é‡æ›å…‰": "double exposure effect, overlapping images, transparent blending, artistic composition",
}

# è² å‘æç¤ºè©é è¨­
NEGATIVE_PROMPTS = {
    "åŸºæœ¬": "blurry, low quality, distorted, deformed, ugly, bad anatomy",
    "æ”å½±": "blurry, low resolution, overexposed, underexposed, noise, grain, amateur",
    "äººåƒ": "bad anatomy, deformed face, extra limbs, missing fingers, asymmetric eyes, ugly",
    "å‹•æ¼«": "realistic, photographic, 3d render, western cartoon, bad anatomy, low quality",
    "è—è¡“": "photographic, realistic, low quality, commercial, amateur, stock photo",
    "å»ºç¯‰": "blurry, distorted perspective, bad proportions, amateur photography, low quality",
}

def rerun_app():
    """å®‰å…¨çš„æ‡‰ç”¨é‡è¼‰å‡½æ•¸"""
    try:
        if hasattr(st, 'rerun'):
            st.rerun()
        elif hasattr(st, 'experimental_rerun'):
            st.experimental_rerun()
        else:
            st.stop()
    except Exception:
        st.stop()

# é é¢é…ç½®
st.set_page_config(
    page_title=APP_TITLE,
    page_icon=APP_ICON,
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®Œæ•´çš„APIä¾›æ‡‰å•†é…ç½®
API_PROVIDERS = {
    "Pollinations.ai": {
        "name": "Pollinations.ai Studio",
        "base_url_default": "https://image.pollinations.ai",
        "icon": "ğŸŒ¸",
        "description": "å…è²»AIåœ–åƒç”Ÿæˆæœå‹™ï¼Œæ”¯æŒå¤šç¨®æ¨¡å‹",
        "hardcoded_models": {
            # FLUX ç³»åˆ—
            "flux-1.1-pro": {"name": "Flux 1.1 Pro", "icon": "ğŸ†", "category": "FLUX", "description": "æœ€æ–°æ——è‰¦ç´šFLUXæ¨¡å‹"},
            "flux.1-kontext-pro": {"name": "Flux.1 Kontext Pro", "icon": "ğŸ§ ", "category": "FLUX", "description": "ä¸Šä¸‹æ–‡ç†è§£å¢å¼·ç‰ˆ"},
            "flux.1-kontext-max": {"name": "Flux.1 Kontext Max", "icon": "ğŸ‘‘", "category": "FLUX", "description": "æœ€å¼·ä¸Šä¸‹æ–‡ç†è§£"},
            "flux-dev": {"name": "Flux Dev", "icon": "ğŸ› ï¸", "category": "FLUX", "description": "é–‹ç™¼è€…ç‰ˆæœ¬"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX", "description": "å¿«é€Ÿç”Ÿæˆç‰ˆæœ¬"},
            "flux-realism": {"name": "Flux Realism", "icon": "ğŸ“·", "category": "FLUX", "description": "å¯«å¯¦é¢¨æ ¼å°ˆç”¨"},
            "flux-anime": {"name": "Flux Anime", "icon": "ğŸŒ", "category": "FLUX", "description": "å‹•æ¼«é¢¨æ ¼å°ˆç”¨"},
            "flux-3d": {"name": "Flux 3D", "icon": "ğŸ¯", "category": "FLUX", "description": "3Dæ¸²æŸ“é¢¨æ ¼"},
            
            # Stable Diffusion ç³»åˆ—
            "stable-diffusion-3.5-large": {"name": "SD 3.5 Large", "icon": "ğŸ¯", "category": "Stable Diffusion", "description": "æœ€æ–°å¤§å‹SDæ¨¡å‹"},
            "stable-diffusion-3.5-medium": {"name": "SD 3.5 Medium", "icon": "âš–ï¸", "category": "Stable Diffusion", "description": "å¹³è¡¡æ€§èƒ½ç‰ˆæœ¬"},
            "stable-diffusion-xl": {"name": "SDXL 1.0", "icon": "ğŸ’", "category": "Stable Diffusion", "description": "é«˜åˆ†è¾¨ç‡æ¨™æº–ç‰ˆ"},
            "stable-diffusion-xl-turbo": {"name": "SDXL Turbo", "icon": "ğŸš€", "category": "Stable Diffusion", "description": "å¿«é€Ÿç”Ÿæˆç‰ˆ"},
            "stable-diffusion-2.1": {"name": "SD 2.1", "icon": "ğŸ”„", "category": "Stable Diffusion", "description": "ç©©å®šç‰ˆæœ¬"},
            "stable-diffusion-1.5": {"name": "SD 1.5", "icon": "ğŸ”°", "category": "Stable Diffusion", "description": "ç¶“å…¸ç‰ˆæœ¬"},
            
            # å°ˆæ¥­ç´šæ¨¡å‹
            "midjourney": {"name": "Midjourney", "icon": "ğŸ­", "category": "Professional", "description": "è—è¡“å‰µä½œå°ˆå®¶"},
            "dalle-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "Professional", "description": "OpenAIæœ€æ–°æ¨¡å‹"},
            "playground-v2.5": {"name": "Playground v2.5", "icon": "ğŸª", "category": "Professional", "description": "å•†æ¥­ç´šæ¨¡å‹"},
            "leonardo-diffusion": {"name": "Leonardo Diffusion", "icon": "ğŸ¨", "category": "Professional", "description": "å°ˆæ¥­å‰µä½œå·¥å…·"},
            
            # ç¤¾å€ç‰¹åŒ–æ¨¡å‹
            "dreamshaper": {"name": "DreamShaper", "icon": "ğŸ’«", "category": "Community", "description": "å¤¢å¢ƒé¢¨æ ¼ç”Ÿæˆ"},
            "realistic-vision": {"name": "Realistic Vision", "icon": "ğŸ‘ï¸", "category": "Community", "description": "è¶…ç¾å¯¦ä¸»ç¾©"},
            "deliberate": {"name": "Deliberate", "icon": "ğŸ¨", "category": "Community", "description": "ç²¾ç´°æ§åˆ¶"},
            "revanimated": {"name": "ReV Animated", "icon": "ğŸ¬", "category": "Community", "description": "å‹•ç•«é¢¨æ ¼"},
            "protogen": {"name": "Protogen", "icon": "ğŸ¤–", "category": "Community", "description": "ç§‘å¹»é¢¨æ ¼"},
            "openjourney": {"name": "OpenJourney", "icon": "ğŸ—ºï¸", "category": "Community", "description": "é–‹æ”¾å¼å‰µä½œ"},
            
            # å‹•æ¼«å°ˆç”¨æ¨¡å‹
            "anything-v5": {"name": "Anything v5", "icon": "ğŸŒŸ", "category": "Anime", "description": "è¬èƒ½å‹•æ¼«æ¨¡å‹"},
            "waifu-diffusion": {"name": "Waifu Diffusion", "icon": "ğŸ‘©â€ğŸ¨", "category": "Anime", "description": "å‹•æ¼«è§’è‰²å°ˆç”¨"},
            "anythingv4": {"name": "Anything v4", "icon": "âœ¨", "category": "Anime", "description": "ç¶“å…¸å‹•æ¼«æ¨¡å‹"},
            "counterfeit": {"name": "Counterfeit", "icon": "ğŸª", "category": "Anime", "description": "é«˜è³ªé‡å‹•æ¼«"},
            "pastel-mix": {"name": "Pastel Mix", "icon": "ğŸŒˆ", "category": "Anime", "description": "æŸ”å’Œè‰²å½©"},
            
            # é¢¨æ ¼ç‰¹åŒ–æ¨¡å‹
            "analog-diffusion": {"name": "Analog Film", "icon": "ğŸ“¸", "category": "Style", "description": "è† ç‰‡æ”å½±é¢¨æ ¼"},
            "synthwave-diffusion": {"name": "Synthwave", "icon": "ğŸŒ†", "category": "Style", "description": "åˆæˆæ³¢é¢¨æ ¼"},
            "cyberpunk-anime": {"name": "Cyberpunk Anime", "icon": "ğŸ¤–", "category": "Style", "description": "è³½åšæœ‹å…‹å‹•æ¼«"},
            "pixel-art-xl": {"name": "Pixel Art XL", "icon": "ğŸ®", "category": "Style", "description": "åƒç´ è—è¡“"},
            "papercut-diffusion": {"name": "Papercut", "icon": "âœ‚ï¸", "category": "Style", "description": "å‰ªç´™è—è¡“"},
            "ink-painting": {"name": "Ink Painting", "icon": "ğŸ–‹ï¸", "category": "Style", "description": "æ°´å¢¨ç•«é¢¨æ ¼"},
        }
    },
    
    "NavyAI": {
        "name": "NavyAI",
        "base_url_default": "https://api.navy/v1",
        "icon": "âš“",
        "description": "å•†æ¥­ç´šAI APIæœå‹™å¹³å°",
        "hardcoded_models": {
            "flux-pro": {"name": "Flux Pro", "icon": "ğŸ†", "category": "FLUX", "description": "å•†æ¥­ç´šFLUX"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX", "description": "å¿«é€Ÿç”Ÿæˆ"},
            "stable-diffusion-xl": {"name": "SDXL", "icon": "ğŸ’", "category": "Stable Diffusion", "description": "é«˜åˆ†è¾¨ç‡"},
            "midjourney-v6": {"name": "Midjourney v6", "icon": "ğŸ­", "category": "Professional", "description": "æœ€æ–°Midjourney"},
            "dalle-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "Professional", "description": "OpenAIæ¨¡å‹"},
        }
    },
    
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "icon": "ğŸ¤—",
        "description": "é–‹æºæ¨¡å‹æ¨ç†å¹³å°",
        "hardcoded_models": {
            "stable-diffusion-v1-5": {"name": "SD 1.5 (HF)", "icon": "ğŸ”°", "category": "Stable Diffusion", "description": "é–‹æºç¶“å…¸"},
            "stable-diffusion-xl-base-1.0": {"name": "SDXL Base (HF)", "icon": "ğŸ’", "category": "Stable Diffusion", "description": "é–‹æºSDXL"},
            "flux-1-dev": {"name": "Flux.1 Dev (HF)", "icon": "ğŸ› ï¸", "category": "FLUX", "description": "é–‹æºFLUX"},
            "stable-diffusion-2-1": {"name": "SD 2.1 (HF)", "icon": "ğŸ”„", "category": "Stable Diffusion", "description": "é–‹æºSD2.1"},
        }
    },
    
    "OpenAI Compatible": {
        "name": "OpenAI å…¼å®¹ API",
        "base_url_default": "https://api.openai.com/v1",
        "icon": "ğŸ¤–",
        "description": "æ¨™æº–OpenAIå…¼å®¹æ¥å£",
        "hardcoded_models": {
            "dall-e-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "OpenAI", "description": "æœ€æ–°DALL-E"},
            "dall-e-2": {"name": "DALL-E 2", "icon": "ğŸ”„", "category": "OpenAI", "description": "ç¶“å…¸DALL-E"},
        }
    }
}

# åŸºç¤æ¨¡å‹é›†åˆï¼ˆå¾Œå‚™é¸é …ï¼‰
BASE_MODELS = {
    "flux.1-schnell": {"name": "FLUX.1 Schnell", "icon": "âš¡", "priority": 1, "category": "FLUX", "description": "å¿«é€ŸFLUXç”Ÿæˆ"},
    "stable-diffusion-xl": {"name": "Stable Diffusion XL", "icon": "ğŸ’", "priority": 2, "category": "Stable Diffusion", "description": "é«˜åˆ†è¾¨ç‡SD"},
    "stable-diffusion-1.5": {"name": "Stable Diffusion 1.5", "icon": "ğŸ”°", "priority": 3, "category": "Stable Diffusion", "description": "ç¶“å…¸SDç‰ˆæœ¬"},
}

# === æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ===

def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    # APIé…ç½®åˆå§‹åŒ–
    if 'api_profiles' not in st.session_state:
        try:
            base_profiles = st.secrets.get("api_profiles", {})
        except StreamlitSecretNotFoundError:
            base_profiles = {}
        
        # é»˜èªé…ç½®
        default_profiles = {
            "é è¨­ Pollinations": {
                'provider': 'Pollinations.ai',
                'api_key': '',
                'base_url': 'https://image.pollinations.ai',
                'validated': True,
                'pollinations_auth_mode': 'å…è²»',
                'pollinations_token': '',
                'pollinations_referrer': ''
            }
        }
        
        st.session_state.api_profiles = base_profiles.copy() if base_profiles else default_profiles
    
    # æ´»å‹•é…ç½®åˆå§‹åŒ–
    if ('active_profile_name' not in st.session_state or 
        st.session_state.active_profile_name not in st.session_state.api_profiles):
        st.session_state.active_profile_name = (
            list(st.session_state.api_profiles.keys())[0] 
            if st.session_state.api_profiles else ""
        )
    
    # å…¶ä»–ç‹€æ…‹åˆå§‹åŒ–
    defaults = {
        'generation_history': [],
        'favorite_images': [],
        'discovered_models': {},
        'selected_model': None,
        'generation_in_progress': False,
        'last_generation_time': None,
        'ui_theme': 'light',
        'advanced_mode': False,
        'batch_processing': False,
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def get_active_config() -> Dict:
    """ç²å–ç•¶å‰æ´»å‹•çš„APIé…ç½®"""
    return st.session_state.api_profiles.get(st.session_state.active_profile_name, {})

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    """é©—è­‰APIå¯†é‘°"""
    try:
        if provider == "Pollinations.ai":
            return True, "Pollinations.ai ç„¡éœ€é©—è­‰"
        
        elif provider == "Hugging Face":
            if not api_key:
                return False, "Hugging Face éœ€è¦ API Token"
            
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.get(f"{base_url}/models", headers=headers, timeout=10)
            
            if response.status_code == 200:
                return True, "Hugging Face API Token é©—è­‰æˆåŠŸ"
            else:
                return False, f"Hugging Face API é©—è­‰å¤±æ•—: {response.status_code}"
        
        else:
            # OpenAIå…¼å®¹APIé©—è­‰
            client = OpenAI(api_key=api_key, base_url=base_url)
            client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
            
    except Exception as e:
        return False, f"API é©—è­‰å¤±æ•—: {str(e)[:100]}"

def auto_discover_models(client, provider: str, base_url: str) -> Dict[str, Dict]:
    """è‡ªå‹•ç™¼ç¾å¯ç”¨æ¨¡å‹"""
    discovered = {}
    
    try:
        if provider == "Pollinations.ai":
            response = requests.get(f"{base_url}/models", timeout=15)
            if response.ok:
                models = response.json()
                for model_name in models:
                    # æ™ºèƒ½åˆ†é¡
                    category = categorize_model_name(model_name)
                    icon = get_model_icon(model_name, category)
                    
                    discovered[model_name] = {
                        "name": format_model_name(model_name),
                        "icon": icon,
                        "category": category,
                        "description": f"Pollinations {category} æ¨¡å‹"
                    }
            else:
                st.warning(f"ç„¡æ³•å¾ Pollinations ç²å–æ¨¡å‹åˆ—è¡¨: HTTP {response.status_code}")
        
        elif provider == "Hugging Face":
            # HFæ¨¡å‹ç™¼ç¾é‚è¼¯
            popular_models = [
                "runwayml/stable-diffusion-v1-5",
                "stabilityai/stable-diffusion-xl-base-1.0",
                "black-forest-labs/flux-schnell",
                "stabilityai/stable-diffusion-2-1",
            ]
            
            for model_id in popular_models:
                category = categorize_model_name(model_id)
                icon = get_model_icon(model_id, category)
                
                discovered[model_id] = {
                    "name": format_model_name(model_id.split('/')[-1]),
                    "icon": icon,
                    "category": category,
                    "description": f"HF {category} æ¨¡å‹"
                }
        
        elif client:
            # OpenAIå…¼å®¹APIæ¨¡å‹ç™¼ç¾
            models = client.models.list().data
            for model in models:
                if any(keyword in model.id.lower() for keyword in 
                      ['flux', 'stable', 'dall', 'midjourney', 'sd', 'xl']):
                    
                    category = categorize_model_name(model.id)
                    icon = get_model_icon(model.id, category)
                    
                    discovered[model.id] = {
                        "name": format_model_name(model.id),
                        "icon": icon,
                        "category": category,
                        "description": f"API {category} æ¨¡å‹"
                    }
    
    except Exception as e:
        st.error(f"æ¨¡å‹ç™¼ç¾å¤±æ•—: {str(e)[:100]}")
    
    return discovered

def categorize_model_name(model_name: str) -> str:
    """æ ¹æ“šæ¨¡å‹åç¨±æ™ºèƒ½åˆ†é¡"""
    name_lower = model_name.lower()
    
    if any(x in name_lower for x in ['flux', 'kontext']):
        return "FLUX"
    elif any(x in name_lower for x in ['stable-diffusion', 'stable_diffusion', 'sd-', 'sdxl']):
        return "Stable Diffusion"
    elif any(x in name_lower for x in ['anime', 'waifu', 'anything', 'counterfeit']):
        return "Anime"
    elif any(x in name_lower for x in ['midjourney', 'dalle', 'playground', 'leonardo']):
        return "Professional"
    elif any(x in name_lower for x in ['analog', 'synthwave', 'cyberpunk', 'pixel']):
        return "Style"
    else:
        return "Community"

def get_model_icon(model_name: str, category: str) -> str:
    """ç²å–æ¨¡å‹åœ–æ¨™"""
    name_lower = model_name.lower()
    
    if 'flux' in name_lower:
        return "âš¡"
    elif 'stable' in name_lower or 'sd' in name_lower:
        return "ğŸ’"
    elif 'dall' in name_lower:
        return "ğŸ¤–"
    elif 'midjourney' in name_lower:
        return "ğŸ­"
    elif 'anime' in name_lower or 'waifu' in name_lower:
        return "ğŸŒ"
    elif category == "Style":
        return "ğŸ¨"
    elif category == "Professional":
        return "ğŸ†"
    else:
        return "ğŸŒŸ"

def format_model_name(model_name: str) -> str:
    """æ ¼å¼åŒ–æ¨¡å‹åç¨±é¡¯ç¤º"""
    # ç§»é™¤å¸¸è¦‹å‰ç¶´
    name = model_name.replace('stabilityai/', '').replace('runwayml/', '')
    name = name.replace('black-forest-labs/', '').replace('-', ' ').replace('_', ' ')
    
    # é¦–å­—æ¯å¤§å¯«
    return ' '.join(word.capitalize() for word in name.split())

def merge_models() -> Dict[str, Dict]:
    """åˆä½µç¡¬ç·¨ç¢¼å’Œç™¼ç¾çš„æ¨¡å‹"""
    provider = get_active_config().get('provider')
    discovered = st.session_state.get('discovered_models', {})
    
    if provider in API_PROVIDERS:
        hardcoded = API_PROVIDERS[provider].get('hardcoded_models', {})
        merged = {**hardcoded, **discovered}
    else:
        merged = {**BASE_MODELS, **discovered}
    
    return merged

def get_models_by_category(models: Dict[str, Dict]) -> Dict[str, Dict[str, Dict]]:
    """æŒ‰é¡åˆ¥çµ„ç¹”æ¨¡å‹"""
    categorized = {}
    for model_id, model_info in models.items():
        category = model_info.get('category', 'Other')
        if category not in categorized:
            categorized[category] = {}
        categorized[category][model_id] = model_info
    
    # æ’åºé¡åˆ¥
    priority_order = ["FLUX", "Stable Diffusion", "Professional", "Anime", "Style", "Community", "Other"]
    sorted_categorized = {}
    
    for category in priority_order:
        if category in categorized:
            sorted_categorized[category] = categorized[category]
    
    # æ·»åŠ å…¶ä»–æœªçŸ¥é¡åˆ¥
    for category, models in categorized.items():
        if category not in sorted_categorized:
            sorted_categorized[category] = models
    
    return sorted_categorized

# === åœ–åƒç”ŸæˆåŠŸèƒ½ ===

def generate_images_with_retry(client, **params) -> Tuple[bool, any]:
    """çµ±ä¸€çš„åœ–åƒç”Ÿæˆå…¥å£"""
    provider = get_active_config().get('provider')
    n_images = params.get("n", 1)
    
    st.session_state.generation_in_progress = True
    
    try:
        if provider == "Pollinations.ai":
            return generate_pollinations_images(params, n_images)
        elif provider == "Hugging Face":
            return generate_huggingface_images(params, n_images)
        else:
            return generate_openai_compatible_images(client, params, n_images)
    finally:
        st.session_state.generation_in_progress = False
        st.session_state.last_generation_time = datetime.datetime.now()

def generate_pollinations_images(params: Dict, n_images: int) -> Tuple[bool, any]:
    """Pollinations.ai åœ–åƒç”Ÿæˆ"""
    generated_images = []
    cfg = get_active_config()
    
    # å‰µå»ºé€²åº¦æ¢
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(n_images):
        try:
            status_text.text(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{n_images} å¼µåœ–ç‰‡...")
            progress_bar.progress((i) / n_images)
            
            current_params = params.copy()
            current_params["seed"] = random.randint(0, 2**32 - 1)
            
            # æ§‹å»ºæç¤ºè©
            prompt = current_params.get("prompt", "")
            if neg_prompt := current_params.get("negative_prompt"):
                prompt += f" --no {neg_prompt}"
            
            # è§£æå°ºå¯¸
            width, height = str(current_params.get("size", "1024x1024")).split('x')
            
            # APIåƒæ•¸
            api_params = {}
            for key, value in {
                "model": current_params.get("model"),
                "width": width,
                "height": height,
                "seed": current_params.get("seed"),
                "nologo": current_params.get("nologo"),
                "private": current_params.get("private"),
                "enhance": current_params.get("enhance"),
                "safe": current_params.get("safe")
            }.items():
                if value is not None:
                    api_params[key] = value
            
            # èªè­‰é ­
            headers = {}
            auth_mode = cfg.get('pollinations_auth_mode', 'å…è²»')
            
            if auth_mode == 'ä»¤ç‰Œ' and cfg.get('pollinations_token'):
                headers['Authorization'] = f"Bearer {cfg['pollinations_token']}"
            elif auth_mode == 'åŸŸå' and cfg.get('pollinations_referrer'):
                headers['Referer'] = cfg['pollinations_referrer']
            
            # ç™¼é€è«‹æ±‚
            url = f"{cfg['base_url']}/prompt/{quote(prompt)}?{urlencode(api_params)}"
            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else:
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {str(e)[:100]}")
            continue
    
    # æ¸…ç†UI
    progress_bar.progress(1.0)
    status_text.text(f"å®Œæˆç”Ÿæˆ {len(generated_images)}/{n_images} å¼µåœ–ç‰‡")
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()
    
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else:
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—"

def generate_huggingface_images(params: Dict, n_images: int) -> Tuple[bool, any]:
    """Hugging Face åœ–åƒç”Ÿæˆ"""
    generated_images = []
    cfg = get_active_config()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(n_images):
        try:
            status_text.text(f"æ­£åœ¨é€šéHFç”Ÿæˆç¬¬ {i+1}/{n_images} å¼µåœ–ç‰‡...")
            progress_bar.progress(i / n_images)
            
            headers = {"Authorization": f"Bearer {cfg['api_key']}"}
            model = params.get("model")
            prompt = params.get("prompt", "")
            
            # HF API payload
            payload = {
                "inputs": prompt,
                "parameters": {
                    "negative_prompt": params.get("negative_prompt", ""),
                    "num_inference_steps": 25,
                    "guidance_scale": 7.5,
                    "width": int(str(params.get("size", "512x512")).split('x')[0]),
                    "height": int(str(params.get("size", "512x512")).split('x')[1]),
                }
            }
            
            url = f"{cfg['base_url']}/models/{model}"
            response = requests.post(url, headers=headers, json=payload, timeout=REQUEST_TIMEOUT)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else:
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {str(e)[:100]}")
            continue
    
    progress_bar.progress(1.0)
    status_text.text(f"å®Œæˆç”Ÿæˆ {len(generated_images)}/{n_images} å¼µåœ–ç‰‡")
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()
    
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else:
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—"

def generate_openai_compatible_images(client, params: Dict, n_images: int) -> Tuple[bool, any]:
    """OpenAIå…¼å®¹APIåœ–åƒç”Ÿæˆ"""
    try:
        sdk_params = {
            "model": params.get("model"),
            "prompt": params.get("prompt"),
            "size": str(params.get("size")),
            "n": n_images,
            "response_format": "b64_json"
        }
        
        # æ·»åŠ è² å‘æç¤ºè©æ”¯æŒï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
        if params.get("negative_prompt"):
            sdk_params["negative_prompt"] = params.get("negative_prompt")
        
        # éæ¿¾ç©ºå€¼
        sdk_params = {k: v for k, v in sdk_params.items() 
                     if v is not None and v != ""}
        
        return True, client.images.generate(**sdk_params)
        
    except Exception as e:
        return False, str(e)[:200]

# === æ­·å²å’Œæ”¶è—ç®¡ç† ===

def add_to_history(prompt: str, negative_prompt: str, model: str, 
                  images: List[str], metadata: Dict):
    """æ·»åŠ åˆ°æ­·å²è¨˜éŒ„"""
    history = st.session_state.generation_history
    
    new_entry = {
        "id": str(uuid.uuid4()),
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "model": model,
        "images": images,
        "metadata": metadata
    }
    
    history.insert(0, new_entry)
    st.session_state.generation_history = history[:MAX_HISTORY_ITEMS]

def display_image_with_actions(b64_json: str, image_id: str, history_item: Dict):
    """é¡¯ç¤ºåœ–ç‰‡åŠæ“ä½œæŒ‰éˆ•"""
    try:
        img_data = base64.b64decode(b64_json)
        img = Image.open(BytesIO(img_data))
        
        # é¡¯ç¤ºåœ–ç‰‡
        st.image(img, use_container_width=True)
        
        # åœ–ç‰‡ä¿¡æ¯
        if st.session_state.get('advanced_mode', False):
            with st.expander("ğŸ” åœ–ç‰‡ä¿¡æ¯"):
                st.json({
                    "å°ºå¯¸": f"{img.size[0]}x{img.size[1]}",
                    "æ¨¡å¼": img.mode,
                    "æ–‡ä»¶å¤§å°": f"{len(img_data)} bytes"
                })
        
        # æ“ä½œæŒ‰éˆ•
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰",
                img_data,
                f"ai_generated_{image_id}.png",
                "image/png",
                key=f"dl_{image_id}",
                use_container_width=True
            )
        
        with col2:
            is_fav = any(fav['id'] == image_id 
                        for fav in st.session_state.favorite_images)
            if st.button(
                "â­" if is_fav else "â˜†",
                key=f"fav_{image_id}",
                use_container_width=True,
                help="æ”¶è—/å–æ¶ˆæ”¶è—"
            ):
                if is_fav:
                    st.session_state.favorite_images = [
                        f for f in st.session_state.favorite_images
                        if f['id'] != image_id
                    ]
                else:
                    if len(st.session_state.favorite_images) < MAX_FAVORITE_ITEMS:
                        st.session_state.favorite_images.append({
                            "id": image_id,
                            "image_b64": b64_json,
                            "timestamp": datetime.datetime.now(),
                            "history_item": history_item
                        })
                    else:
                        st.warning(f"æ”¶è—å·²é”ä¸Šé™ ({MAX_FAVORITE_ITEMS})")
                rerun_app()
        
        with col3:
            if st.button(
                "ğŸ¨ è®Šé«”",
                key=f"vary_{image_id}",
                use_container_width=True,
                help="ä½¿ç”¨æ­¤æç¤ºç”Ÿæˆè®Šé«”"
            ):
                st.session_state.update({
                    'vary_prompt': history_item['prompt'],
                    'vary_negative_prompt': history_item.get('negative_prompt', ''),
                    'vary_model': history_item['model']
                })
                rerun_app()
                
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {str(e)[:100]}")

# === APIå®¢æˆ¶ç«¯ç®¡ç† ===

def init_api_client():
    """åˆå§‹åŒ–APIå®¢æˆ¶ç«¯"""
    cfg = get_active_config()
    if (cfg and cfg.get('api_key') and 
        cfg.get('provider') not in ["Pollinations.ai", "Hugging Face"]):
        try:
            return OpenAI(api_key=cfg['api_key'], base_url=cfg['base_url'])
        except Exception:
            return None
    return None

# === UIçµ„ä»¶ ===

def editor_provider_changed():
    """ä¾›æ‡‰å•†è®Šæ›´å›èª¿"""
    provider = st.session_state.editor_provider_selectbox
    st.session_state.editor_base_url = API_PROVIDERS[provider]['base_url_default']
    st.session_state.editor_api_key = ""

def load_profile_to_editor_state(profile_name: str):
    """åŠ è¼‰é…ç½®åˆ°ç·¨è¼¯å™¨ç‹€æ…‹"""
    config = st.session_state.api_profiles.get(profile_name, {})
    provider = config.get('provider', 'Pollinations.ai')
    
    st.session_state.editor_provider_selectbox = provider
    st.session_state.editor_base_url = config.get(
        'base_url',
        API_PROVIDERS.get(provider, {}).get('base_url_default', '')
    )
    st.session_state.editor_api_key = config.get('api_key', '')
    st.session_state.editor_auth_mode = config.get('pollinations_auth_mode', 'å…è²»')
    st.session_state.editor_referrer = config.get('pollinations_referrer', '')
    st.session_state.editor_token = config.get('pollinations_token', '')
    st.session_state.profile_being_edited = profile_name

def show_api_settings():
    """é¡¯ç¤ºAPIè¨­ç½®é¢æ¿"""
    st.subheader("âš™ï¸ API å­˜æª”ç®¡ç†")
    
    profile_names = list(st.session_state.api_profiles.keys())
    if not profile_names:
        st.warning("æ²’æœ‰å¯ç”¨çš„ API å­˜æª”ã€‚è«‹æ–°å¢ä¸€å€‹ã€‚")
        return
    
    # é¸æ“‡æ´»å‹•é…ç½®
    current_index = (profile_names.index(st.session_state.get('active_profile_name'))
                    if st.session_state.get('active_profile_name') in profile_names
                    else 0)
    
    active_profile_name = st.selectbox(
        "æ´»å‹•å­˜æª”",
        profile_names,
        index=current_index,
        help="é¸æ“‡è¦ä½¿ç”¨çš„APIé…ç½®"
    )
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡è¼‰
    if (st.session_state.get('active_profile_name') != active_profile_name or
        'profile_being_edited' not in st.session_state or
        st.session_state.profile_being_edited != active_profile_name):
        
        st.session_state.active_profile_name = active_profile_name
        load_profile_to_editor_state(active_profile_name)
        st.session_state.discovered_models = {}
        rerun_app()
    
    # é…ç½®ç®¡ç†æŒ‰éˆ•
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("â• æ–°å¢å­˜æª”", use_container_width=True):
            new_name = "æ–°å­˜æª”"
            count = 1
            while new_name in st.session_state.api_profiles:
                new_name = f"æ–°å­˜æª”_{count}"
                count += 1
            
            st.session_state.api_profiles[new_name] = {
                'provider': 'Pollinations.ai',
                'validated': False,
                'base_url': API_PROVIDERS['Pollinations.ai']['base_url_default']
            }
            st.session_state.active_profile_name = new_name
            rerun_app()
    
    with col2:
        if st.button(
            "ğŸ—‘ï¸ åˆªé™¤ç•¶å‰å­˜æª”",
            use_container_width=True,
            disabled=len(profile_names) <= 1 or not active_profile_name
        ):
            if active_profile_name and len(profile_names) > 1:
                del st.session_state.api_profiles[active_profile_name]
                st.session_state.active_profile_name = list(st.session_state.api_profiles.keys())[0]
                rerun_app()
    
    # ç·¨è¼¯ç•¶å‰é…ç½®
    if active_profile_name:
        show_profile_editor(active_profile_name)

def show_profile_editor(profile_name: str):
    """é¡¯ç¤ºé…ç½®ç·¨è¼¯å™¨"""
    with st.expander("ğŸ“ ç·¨è¼¯ç•¶å‰æ´»å‹•å­˜æª”", expanded=True):
        # åŸºæœ¬ä¿¡æ¯
        st.text_input(
            "å­˜æª”åç¨±",
            value=profile_name,
            key="editor_profile_name",
            help="ç‚ºæ­¤APIé…ç½®è¨­ç½®ä¸€å€‹æ˜“è­˜åˆ¥çš„åç¨±"
        )
        
        # ä¾›æ‡‰å•†é¸æ“‡
        provider_options = list(API_PROVIDERS.keys())
        st.selectbox(
            "API æä¾›å•†",
            provider_options,
            key='editor_provider_selectbox',
            on_change=editor_provider_changed,
            help="é¸æ“‡æ‚¨çš„APIæœå‹™æä¾›å•†"
        )
        
        # ç«¯é»URL
        st.text_input(
            "API ç«¯é» URL",
            key='editor_base_url',
            help="APIæœå‹™çš„åŸºç¤URL"
        )
        
        provider = st.session_state.editor_provider_selectbox
        
        # ç‰¹å®šä¾›æ‡‰å•†é…ç½®
        if provider == "Pollinations.ai":
            show_pollinations_config()
        else:
            st.text_input(
                "API å¯†é‘°",
                key='editor_api_key',
                type="password",
                help="æ‚¨çš„APIå¯†é‘°æˆ–ä»¤ç‰Œ"
            )
        
        # ä¿å­˜æŒ‰éˆ•
        if st.button("ğŸ’¾ ä¿å­˜/æ›´æ–°å­˜æª”", type="primary"):
            save_profile_config(profile_name, provider)

def show_pollinations_config():
    """é¡¯ç¤ºPollinations.aiç‰¹å®šé…ç½®"""
    st.radio(
        "èªè­‰æ¨¡å¼",
        ["å…è²»", "åŸŸå", "ä»¤ç‰Œ"],
        key='editor_auth_mode',
        horizontal=True,
        help="é¸æ“‡Pollinations.aiçš„èªè­‰æ–¹å¼"
    )
    
    if st.session_state.editor_auth_mode == 'åŸŸå':
        st.text_input(
            "æ‡‰ç”¨åŸŸå (Referrer)",
            key='editor_referrer',
            help="æ‚¨çš„æ‡‰ç”¨ç¶²åŸŸï¼Œç”¨æ–¼åŸŸåé©—è­‰"
        )
    
    if st.session_state.editor_auth_mode == 'ä»¤ç‰Œ':
        st.text_input(
            "API ä»¤ç‰Œ (Token)",
            key='editor_token',
            type="password",
            help="Pollinations.aiçš„ä»˜è²»APIä»¤ç‰Œ"
        )

def save_profile_config(profile_name: str, provider: str):
    """ä¿å­˜é…ç½®"""
    new_config = {
        'provider': provider,
        'base_url': st.session_state.editor_base_url
    }
    
    if provider == "Pollinations.ai":
        new_config.update({
            'api_key': '',
            'pollinations_auth_mode': st.session_state.editor_auth_mode,
            'pollinations_referrer': st.session_state.get('editor_referrer', ''),
            'pollinations_token': st.session_state.get('editor_token', '')
        })
    else:
        new_config.update({
            'api_key': st.session_state.editor_api_key,
            'pollinations_auth_mode': 'å…è²»',
            'pollinations_referrer': '',
            'pollinations_token': ''
        })
    
    # é©—è­‰é…ç½®
    is_valid, msg = validate_api_key(
        new_config['api_key'],
        new_config['base_url'],
        new_config['provider']
    )
    new_config['validated'] = is_valid
    
    # ä¿å­˜é…ç½®
    new_name = st.session_state.editor_profile_name
    if new_name != profile_name:
        del st.session_state.api_profiles[profile_name]
    
    st.session_state.api_profiles[new_name] = new_config
    st.session_state.active_profile_name = new_name
    
    # é¡¯ç¤ºçµæœ
    if is_valid:
        st.success(f"å­˜æª” '{new_name}' å·²ä¿å­˜ä¸¦é©—è­‰æˆåŠŸï¼")
    else:
        st.warning(f"å­˜æª” '{new_name}' å·²ä¿å­˜ï¼Œä½†é©—è­‰å¤±æ•—: {msg}")
    
    time.sleep(1.5)
    rerun_app()

def show_model_selector(all_models: Dict[str, Dict]) -> Optional[str]:
    """é¡¯ç¤ºæ¨¡å‹é¸æ“‡å™¨"""
    if not all_models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹ã€‚è«‹åœ¨å´é‚Šæ¬„é…ç½®APIæˆ–é»æ“Šã€Œç™¼ç¾æ¨¡å‹ã€ã€‚")
        return None
    
    categorized_models = get_models_by_category(all_models)
    
    # ç²å–ç•¶å‰é¸ä¸­çš„æ¨¡å‹
    current_selection = st.session_state.get('selected_model')
    if current_selection not in all_models:
        current_selection = list(all_models.keys())[0]
        st.session_state.selected_model = current_selection
    
    # é¡¯ç¤ºç•¶å‰é¸ä¸­çš„æ¨¡å‹
    if current_selection:
        model_info = all_models[current_selection]
        st.success(
            f"ğŸ¯ ç•¶å‰æ¨¡å‹: {model_info.get('icon', 'ğŸ¤–')} "
            f"{model_info.get('name', current_selection)}"
        )
        
        if model_info.get('description'):
            st.caption(f"ğŸ“ {model_info['description']}")
    
    st.markdown("---")
    
    # çµ±è¨ˆä¿¡æ¯
    total_models = len(all_models)
    categories_count = len(categorized_models)
    st.caption(f"ğŸ“Š å¯ç”¨æ¨¡å‹: **{total_models}** å€‹ï¼Œåˆ†ç‚º **{categories_count}** å€‹é¡åˆ¥")
    
    # å¿«é€Ÿæœç´¢
    search_term = st.text_input(
        "ğŸ” æœç´¢æ¨¡å‹",
        placeholder="è¼¸å…¥æ¨¡å‹åç¨±æˆ–é—œéµè©...",
        help="å¿«é€Ÿæœç´¢ç‰¹å®šæ¨¡å‹"
    )
    
    # éæ¿¾æ¨¡å‹
    if search_term:
        filtered_models = {}
        for model_id, model_info in all_models.items():
            if (search_term.lower() in model_id.lower() or
                search_term.lower() in model_info.get('name', '').lower()):
                filtered_models[model_id] = model_info
        
        if filtered_models:
            st.write(f"ğŸ” æ‰¾åˆ° {len(filtered_models)} å€‹åŒ¹é…çš„æ¨¡å‹:")
            show_model_grid(filtered_models, "æœç´¢çµæœ")
        else:
            st.warning("ğŸ” æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„æ¨¡å‹")
        
        return current_selection
    
    # æŒ‰é¡åˆ¥é¡¯ç¤ºæ¨¡å‹
    for category, models in categorized_models.items():
        show_model_grid(models, category)
    
    return current_selection

def show_model_grid(models: Dict[str, Dict], category_name: str):
    """é¡¯ç¤ºæ¨¡å‹ç¶²æ ¼"""
    with st.expander(f"ğŸ“ {category_name} ({len(models)} å€‹æ¨¡å‹)", expanded=True):
        # å‰µå»ºç¶²æ ¼å¸ƒå±€
        cols = st.columns(3)
        
        for i, (model_id, model_info) in enumerate(models.items()):
            col = cols[i % 3]
            
            with col:
                # æ¨¡å‹æŒ‰éˆ•
                button_text = f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', model_id)}"
                is_selected = st.session_state.get('selected_model') == model_id
                
                if st.button(
                    button_text,
                    key=f"select_model_{model_id}_{category_name}",
                    use_container_width=True,
                    type="primary" if is_selected else "secondary"
                ):
                    st.session_state.selected_model = model_id
                    rerun_app()
                
                # æ¨¡å‹æè¿°
                if model_info.get('description') and st.session_state.get('advanced_mode'):
                    st.caption(model_info['description'])

def show_generation_interface():
    """é¡¯ç¤ºç”Ÿæˆç•Œé¢"""
    # ç²å–è®Šé«”åƒæ•¸
    prompt_default = st.session_state.pop('vary_prompt', '')
    neg_prompt_default = st.session_state.pop('vary_negative_prompt', '')
    
    # ä¸»è¦åƒæ•¸è¨­ç½®
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # é¢¨æ ¼é¸æ“‡
        selected_style = st.selectbox(
            "ğŸ¨ é¢¨æ ¼é è¨­",
            list(STYLE_PRESETS.keys()),
            help="é¸æ“‡é å®šç¾©çš„è—è¡“é¢¨æ ¼"
        )
        
        # æç¤ºè©
        prompt_val = st.text_area(
            "âœï¸ æç¤ºè©",
            value=prompt_default,
            height=120,
            placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒï¼Œè¶Šè©³ç´°è¶Šå¥½...",
            help="è©³ç´°æè¿°æ‚¨æƒ³è¦çš„åœ–åƒå…§å®¹ã€é¢¨æ ¼ã€æ§‹åœ–ç­‰"
        )
        
        # è² å‘æç¤ºè©é¸æ“‡
        neg_preset = st.selectbox(
            "ğŸš« è² å‘æç¤ºè©é è¨­",
            list(NEGATIVE_PROMPTS.keys()),
            help="é¸æ“‡é å®šç¾©çš„è² å‘æç¤ºè©"
        )
        
        # è² å‘æç¤ºè©
        negative_prompt_val = st.text_area(
            "ğŸš« è² å‘æç¤ºè©ï¼ˆå¯é¸ï¼‰",
            value=neg_prompt_default or NEGATIVE_PROMPTS.get(neg_preset, ""),
            height=80,
            placeholder="æè¿°æ‚¨ä¸æƒ³è¦çš„å…§å®¹...",
            help="æŒ‡å®šæ‚¨ä¸å¸Œæœ›å‡ºç¾åœ¨åœ–åƒä¸­çš„å…ƒç´ "
        )
    
    with col2:
        # ç”Ÿæˆåƒæ•¸
        n_images = st.slider(
            "ğŸ–¼ï¸ ç”Ÿæˆæ•¸é‡",
            1, MAX_BATCH_SIZE, 1,
            help=f"ä¸€æ¬¡ç”Ÿæˆçš„åœ–ç‰‡æ•¸é‡ï¼ˆæœ€å¤§ {MAX_BATCH_SIZE}ï¼‰"
        )
        
        # åœ–åƒå°ºå¯¸
        size_preset = st.selectbox(
            "ğŸ“ åœ–åƒå°ºå¯¸",
            options=list(IMAGE_SIZES.keys()),
            format_func=lambda x: IMAGE_SIZES[x],
            help="é¸æ“‡åœ–åƒçš„å°ºå¯¸æ¯”ä¾‹"
        )
        
        # è‡ªå®šç¾©å°ºå¯¸
        if size_preset == "è‡ªå®šç¾©...":
            col_w, col_h = st.columns(2)
            with col_w:
                width = st.slider("å¯¬åº¦", 256, 2048, 1024, 64)
            with col_h:
                height = st.slider("é«˜åº¦", 256, 2048, 1024, 64)
            final_size_str = f"{width}x{height}"
        else:
            final_size_str = size_preset
        
        # é«˜ç´šé¸é …åˆ‡æ›
        st.session_state.advanced_mode = st.toggle(
            "ğŸ”§ é«˜ç´šé¸é …",
            value=st.session_state.get('advanced_mode', False)
        )
    
    return {
        'prompt': prompt_val,
        'negative_prompt': negative_prompt_val,
        'style': selected_style,
        'size': final_size_str,
        'n_images': n_images
    }

def show_advanced_options(provider: str) -> Dict:
    """é¡¯ç¤ºé«˜ç´šé¸é …"""
    options = {}
    
    if not st.session_state.get('advanced_mode', False):
        return options
    
    with st.expander("ğŸ”§ é«˜ç´šç”Ÿæˆåƒæ•¸", expanded=True):
        if provider == "Pollinations.ai":
            col1, col2 = st.columns(2)
            
            with col1:
                options['enhance'] = st.checkbox(
                    "âœ¨ å¢å¼·æç¤ºè©",
                    value=True,
                    help="è‡ªå‹•å„ªåŒ–å’Œè±å¯Œæç¤ºè©"
                )
                options['private'] = st.checkbox(
                    "ğŸ”’ ç§å¯†æ¨¡å¼",
                    value=True,
                    help="ä¸åœ¨å…¬å…±ç•«å»Šä¸­é¡¯ç¤º"
                )
            
            with col2:
                options['nologo'] = st.checkbox(
                    "ğŸš« ç§»é™¤æ¨™èªŒ",
                    value=True,
                    help="ç§»é™¤ç”Ÿæˆåœ–ç‰‡ä¸Šçš„æ°´å°"
                )
                options['safe'] = st.checkbox(
                    "ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼",
                    value=False,
                    help="å•Ÿç”¨å…§å®¹å®‰å…¨éæ¿¾"
                )
        
        elif provider == "Hugging Face":
            col1, col2 = st.columns(2)
            
            with col1:
                options['num_inference_steps'] = st.slider(
                    "æ¨ç†æ­¥é©Ÿ",
                    10, 100, 25,
                    help="æ›´å¤šæ­¥é©Ÿé€šå¸¸ç”¢ç”Ÿæ›´å¥½è³ªé‡"
                )
                options['guidance_scale'] = st.slider(
                    "å¼•å°å¼·åº¦",
                    1.0, 20.0, 7.5, 0.5,
                    help="æ§åˆ¶å°æç¤ºè©çš„éµå¾ªç¨‹åº¦"
                )
            
            with col2:
                options['scheduler'] = st.selectbox(
                    "èª¿åº¦å™¨",
                    ["DPMSolverMultistep", "EulerDiscrete", "DDIM", "PNDMScheduler"],
                    help="é¸æ“‡æ¡æ¨£èª¿åº¦å™¨"
                )
    
    return options

# === ä¸»æ‡‰ç”¨é‚è¼¯ ===

def main():
    """ä¸»æ‡‰ç”¨å‡½æ•¸"""
    # åˆå§‹åŒ–
    init_session_state()
    client = init_api_client()
    cfg = get_active_config()
    api_configured = cfg and cfg.get('validated', False)
    
    # å´é‚Šæ¬„
    with st.sidebar:
        show_sidebar(api_configured, client, cfg)
    
    # ä¸»æ¨™é¡Œ
    st.title(APP_TITLE)
    st.caption(f"æ”¯æ´ FLUXã€Stable Diffusionã€DALL-E åŠæ›´å¤šæ¨¡å‹ | {VERSION}")
    
    # ä¸»ç•Œé¢æ¨™ç±¤é 
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸš€ ç”Ÿæˆåœ–åƒ",
        f"ğŸ“š æ­·å² ({len(st.session_state.generation_history)})",
        f"â­ æ”¶è— ({len(st.session_state.favorite_images)})",
        "â„¹ï¸ é—œæ–¼"
    ])
    
    with tab1:
        show_generation_tab(api_configured, client)
    
    with tab2:
        show_history_tab()
    
    with tab3:
        show_favorites_tab()
    
    with tab4:
        show_about_tab()
    
    # é è…³
    show_footer()

def show_sidebar(api_configured: bool, client, cfg: Dict):
    """é¡¯ç¤ºå´é‚Šæ¬„"""
    show_api_settings()
    
    st.markdown("---")
    
    # APIç‹€æ…‹é¡¯ç¤º
    if api_configured:
        provider_info = API_PROVIDERS.get(cfg['provider'], {})
        st.success(f"ğŸŸ¢ å·²é€£æ¥: {st.session_state.active_profile_name}")
        st.info(f"{provider_info.get('icon', 'ğŸ¤–')} {provider_info.get('name', cfg['provider'])}")
        
        # æ¨¡å‹ç™¼ç¾
        can_discover = (client is not None) or (cfg.get('provider') in ["Pollinations.ai", "Hugging Face"])
        
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True, disabled=not can_discover):
            with st.spinner("ğŸ” æ­£åœ¨ç™¼ç¾å¯ç”¨æ¨¡å‹..."):
                discovered = auto_discover_models(client, cfg['provider'], cfg['base_url'])
                st.session_state.discovered_models = discovered
                
                if discovered:
                    st.success(f"âœ… ç™¼ç¾ {len(discovered)} å€‹æ–°æ¨¡å‹ï¼")
                else:
                    st.warning("âš ï¸ æœªç™¼ç¾æ–°æ¨¡å‹")
                
                time.sleep(1)
                rerun_app()
    
    elif st.session_state.api_profiles:
        st.error(f"ğŸ”´ é…ç½®éŒ¯èª¤: '{st.session_state.active_profile_name}' æœªé©—è­‰")
    else:
        st.warning("âš ï¸ è«‹é…ç½®è‡³å°‘ä¸€å€‹APIä¾›æ‡‰å•†")
    
    st.markdown("---")
    
    # çµ±è¨ˆä¿¡æ¯
    st.info(f"""
    **ğŸ“Š ä½¿ç”¨çµ±è¨ˆ**
    - æ­·å²è¨˜éŒ„: {len(st.session_state.generation_history)}/{MAX_HISTORY_ITEMS}
    - æ”¶è—åœ–ç‰‡: {len(st.session_state.favorite_images)}/{MAX_FAVORITE_ITEMS}
    - æ‰¹æ¬¡ä¸Šé™: {MAX_BATCH_SIZE}
    """)
    
    # å¿«æ·æ“ä½œ
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ­·å²", use_container_width=True):
        st.session_state.generation_history = []
        st.success("æ­·å²è¨˜éŒ„å·²æ¸…ç©º")
        time.sleep(1)
        rerun_app()
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ”¶è—", use_container_width=True):
        st.session_state.favorite_images = []
        st.success("æ”¶è—å·²æ¸…ç©º")
        time.sleep(1)
        rerun_app()

def show_generation_tab(api_configured: bool, client):
    """é¡¯ç¤ºç”Ÿæˆæ¨™ç±¤é """
    if not api_configured:
        st.warning("âš ï¸ è«‹åœ¨å´é‚Šæ¬„é…ç½®ä¸¦é©—è­‰APIä¾›æ‡‰å•†")
        return
    
    # ç²å–å¯ç”¨æ¨¡å‹
    all_models = merge_models()
    if not all_models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨æ¨¡å‹ã€‚è«‹åœ¨å´é‚Šæ¬„é»æ“Šã€Œç™¼ç¾æ¨¡å‹ã€")
        return
    
    # æ¨¡å‹é¸æ“‡
    selected_model = show_model_selector(all_models)
    if not selected_model:
        return
    
    st.markdown("---")
    
    # ç”Ÿæˆåƒæ•¸è¨­ç½®
    gen_params = show_generation_interface()
    
    # é«˜ç´šé¸é …
    cfg = get_active_config()
    advanced_options = show_advanced_options(cfg.get('provider', ''))
    
    # ç”ŸæˆæŒ‰éˆ•å’Œé‚è¼¯
    generation_disabled = (
        not gen_params['prompt'].strip() or
        st.session_state.get('generation_in_progress', False)
    )
    
    button_text = "ğŸ¨ æ­£åœ¨ç”Ÿæˆ..." if st.session_state.get('generation_in_progress') else "ğŸš€ ç”Ÿæˆåœ–åƒ"
    
    if st.button(
        button_text,
        type="primary",
        use_container_width=True,
        disabled=generation_disabled
    ):
        # æ§‹å»ºæœ€çµ‚æç¤ºè©
        final_prompt = gen_params['prompt']
        if gen_params['style'] != "ç„¡" and STYLE_PRESETS[gen_params['style']]:
            final_prompt = f"{final_prompt}, {STYLE_PRESETS[gen_params['style']]}"
        
        # ç”Ÿæˆåƒæ•¸
        params = {
            "model": selected_model,
            "prompt": final_prompt,
            "negative_prompt": gen_params['negative_prompt'],
            "size": gen_params['size'],
            "n": gen_params['n_images'],
            **advanced_options
        }
        
        # é¡¯ç¤ºç”Ÿæˆä¿¡æ¯
        model_name = all_models[selected_model]['name']
        with st.spinner(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨ {model_name} ç”Ÿæˆ {gen_params['n_images']} å¼µåœ–åƒ..."):
            success, result = generate_images_with_retry(client, **params)
        
        # è™•ç†çµæœ
        if success and hasattr(result, 'data') and result.data:
            img_b64s = [img.b64_json for img in result.data]
            
            # æ·»åŠ åˆ°æ­·å²
            add_to_history(
                gen_params['prompt'],
                gen_params['negative_prompt'],
                selected_model,
                img_b64s,
                {
                    "size": gen_params['size'],
                    "provider": cfg['provider'],
                    "style": gen_params['style'],
                    "n": gen_params['n_images'],
                    "model_name": model_name,
                    "advanced_options": advanced_options
                }
            )
            
            st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(img_b64s)} å¼µåœ–åƒï¼")
            
            # é¡¯ç¤ºç”Ÿæˆçš„åœ–åƒ
            if len(img_b64s) == 1:
                display_image_with_actions(
                    img_b64s[0],
                    f"{st.session_state.generation_history[0]['id']}_0",
                    st.session_state.generation_history[0]
                )
            else:
                cols = st.columns(2)
                for i, b64_json in enumerate(img_b64s):
                    with cols[i % 2]:
                        display_image_with_actions(
                            b64_json,
                            f"{st.session_state.generation_history[0]['id']}_{i}",
                            st.session_state.generation_history[0]
                        )
            
            # æ¸…ç†å…§å­˜
            gc.collect()
        
        else:
            st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")

def show_history_tab():
    """é¡¯ç¤ºæ­·å²æ¨™ç±¤é """
    if not st.session_state.generation_history:
        st.info("ğŸ“­ é‚„æ²’æœ‰ç”Ÿæˆæ­·å²ã€‚å¿«å»ç”Ÿæˆä¸€äº›åœ–ç‰‡å§ï¼")
        return
    
    st.subheader(f"ğŸ“š ç”Ÿæˆæ­·å² ({len(st.session_state.generation_history)} æ¢è¨˜éŒ„)")
    
    # æ­·å²è¨˜éŒ„æ“ä½œ
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ­·å²"):
            st.session_state.generation_history = []
            rerun_app()
    
    # é¡¯ç¤ºæ­·å²è¨˜éŒ„
    for item in st.session_state.generation_history:
        timestamp_str = item['timestamp'].strftime('%m-%d %H:%M')
        
        # ç²å–æ¨¡å‹ä¿¡æ¯
        all_models = merge_models()
        model_info = all_models.get(item['model'], {})
        model_name = model_info.get('name', item['model'])
        
        with st.expander(
            f"ğŸ¨ {item['prompt'][:60]}{'...' if len(item['prompt']) > 60 else ''} "
            f"| {model_name} | {timestamp_str}"
        ):
            # é¡¯ç¤ºè©³ç´°ä¿¡æ¯
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown(f"**âœï¸ æç¤ºè©:** {item['prompt']}")
                if item.get('negative_prompt'):
                    st.markdown(f"**ğŸš« è² å‘æç¤ºè©:** {item['negative_prompt']}")
            
            with col2:
                st.markdown(f"**ğŸ¤– æ¨¡å‹:** {model_name}")
                if item.get('metadata', {}).get('style'):
                    st.markdown(f"**ğŸ¨ é¢¨æ ¼:** {item['metadata']['style']}")
                if item.get('metadata', {}).get('size'):
                    st.markdown(f"**ğŸ“ å°ºå¯¸:** {item['metadata']['size']}")
            
            # é¡¯ç¤ºåœ–åƒ
            if len(item['images']) == 1:
                display_image_with_actions(
                    item['images'][0],
                    f"hist_{item['id']}_0",
                    item
                )
            else:
                cols = st.columns(2)
                for i, b64_json in enumerate(item['images']):
                    with cols[i % 2]:
                        display_image_with_actions(
                            b64_json,
                            f"hist_{item['id']}_{i}",
                            item
                        )

def show_favorites_tab():
    """é¡¯ç¤ºæ”¶è—æ¨™ç±¤é """
    if not st.session_state.favorite_images:
        st.info("â­ é‚„æ²’æœ‰æ”¶è—çš„åœ–åƒã€‚åœ¨ç”Ÿæˆçš„åœ–ç‰‡ä¸Šé»æ“Šæ˜Ÿè™Ÿæ”¶è—å§ï¼")
        return
    
    st.subheader(f"â­ æˆ‘çš„æ”¶è— ({len(st.session_state.favorite_images)} å¼µ)")
    
    # æ”¶è—æ“ä½œ
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ”¶è—"):
            st.session_state.favorite_images = []
            rerun_app()
    
    # é¡¯ç¤ºæ”¶è—çš„åœ–åƒ
    sorted_favorites = sorted(
        st.session_state.favorite_images,
        key=lambda x: x['timestamp'],
        reverse=True
    )
    
    cols = st.columns(3)
    for i, fav in enumerate(sorted_favorites):
        with cols[i % 3]:
            display_image_with_actions(
                fav['image_b64'],
                fav['id'],
                fav.get('history_item', {})
            )
            
            # æ”¶è—æ™‚é–“
            fav_time = fav['timestamp'].strftime('%m-%d %H:%M')
            st.caption(f"â­ æ”¶è—æ–¼: {fav_time}")

def show_about_tab():
    """é¡¯ç¤ºé—œæ–¼æ¨™ç±¤é """
    st.markdown("""
    # ğŸ¨ AI åœ–åƒç”Ÿæˆå™¨ - å®Œæ•´å¤šæ¨¡å‹ç‰ˆ
    
    é€™æ˜¯ä¸€å€‹åŠŸèƒ½å¼·å¤§çš„AIåœ–åƒç”Ÿæˆæ‡‰ç”¨ï¼Œæ”¯æŒå¤šç¨®é ‚ç´šAIæ¨¡å‹å’Œä¾›æ‡‰å•†ã€‚
    
    ## âœ¨ ä¸»è¦ç‰¹æ€§
    
    ### ğŸ¤– å¤šæ¨¡å‹æ”¯æŒ
    - **FLUX ç³»åˆ—**: æœ€æ–°çš„é«˜è³ªé‡åœ–åƒç”Ÿæˆæ¨¡å‹
    - **Stable Diffusion**: å¾SD 1.5åˆ°SD 3.5çš„å®Œæ•´ç³»åˆ—
    - **å°ˆæ¥­æ¨¡å‹**: DALL-E 3ã€Midjourneyç­‰é ‚ç´šæ¨¡å‹
    - **ç‰¹åŒ–æ¨¡å‹**: å‹•æ¼«ã€é¢¨æ ¼åŒ–ã€ç¤¾å€èª¿å„ªæ¨¡å‹
    
    ### ğŸ”Œ å¤šä¾›æ‡‰å•†é›†æˆ
    - **Pollinations.ai**: å…è²»é–‹æ”¾å¹³å°
    - **Hugging Face**: é–‹æºæ¨¡å‹ä¸­å¿ƒ
    - **NavyAI**: å•†æ¥­ç´šAPIæœå‹™
    - **OpenAI Compatible**: æ¨™æº–å…¼å®¹æ¥å£
    
    ### ğŸ¨ è±å¯Œçš„å‰µä½œå·¥å…·
    - **30+ é¢¨æ ¼é è¨­**: å¾æ”å½±åˆ°è—è¡“æµæ´¾
    - **æ™ºèƒ½æç¤ºè©**: é è¨­å’Œè‡ªå®šç¾©çµ„åˆ
    - **æ‰¹é‡ç”Ÿæˆ**: ä¸€æ¬¡ç”Ÿæˆå¤šå¼µåœ–ç‰‡
    - **æ­·å²ç®¡ç†**: è‡ªå‹•ä¿å­˜å’Œæ”¶è—ç³»çµ±
    
    ### ğŸ› ï¸ é«˜ç´šåŠŸèƒ½
    - **åˆ†é¡ç®¡ç†**: æŒ‰æ¨¡å‹é¡å‹çµ„ç¹”
    - **æœç´¢åŠŸèƒ½**: å¿«é€Ÿæ‰¾åˆ°ç›®æ¨™æ¨¡å‹
    - **åƒæ•¸æ§åˆ¶**: å°ˆæ¥­ç´šç”Ÿæˆåƒæ•¸
    - **å¤šæ ¼å¼æ”¯æŒ**: å„ç¨®å°ºå¯¸å’Œæ¯”ä¾‹
    
    ## ğŸš€ ä½¿ç”¨å»ºè­°
    
    ### é¸æ“‡åˆé©çš„æ¨¡å‹
    - **å¯«å¯¦ç…§ç‰‡**: SD 3.5 Large, Realistic Vision
    - **è—è¡“å‰µä½œ**: Midjourney, DALL-E 3
    - **å‹•æ¼«é¢¨æ ¼**: Anything v5, Waifu Diffusion
    - **å¿«é€Ÿé è¦½**: Flux Schnell, SDXL Turbo
    
    ### å„ªåŒ–æç¤ºè©
    - ä½¿ç”¨å…·é«”è€Œè©³ç´°çš„æè¿°
    - çµåˆé¢¨æ ¼é è¨­å¢å¼·æ•ˆæœ
    - åˆ©ç”¨è² å‘æç¤ºè©é¿å…ä¸éœ€è¦çš„å…§å®¹
    - åƒè€ƒæˆåŠŸçš„æ­·å²è¨˜éŒ„
    
    ## ğŸ“ æŠ€è¡“æ”¯æŒ
    
    å¦‚æœé‡åˆ°å•é¡Œæˆ–éœ€è¦å¹«åŠ©:
    1. æª¢æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¢º
    2. ç¢ºèªç¶²çµ¡é€£æ¥ç©©å®š
    3. æŸ¥çœ‹æ¨¡å‹æ˜¯å¦æ”¯æŒç•¶å‰åƒæ•¸
    4. åƒè€ƒå„ä¾›æ‡‰å•†çš„ä½¿ç”¨é™åˆ¶
    
    ## ğŸ”— ç›¸é—œè³‡æº
    
    - [Pollinations.ai](https://pollinations.ai/)
    - [Hugging Face](https://huggingface.co/)
    - [NavyAI](https://api.navy/)
    - [OpenAI](https://openai.com/)
    
    ---
    
    **ç‰ˆæœ¬**: {VERSION}  
    **æ›´æ–°æ™‚é–“**: 2025å¹´10æœˆ  
    **é–‹ç™¼æ¡†æ¶**: Streamlit + Python
    """.format(VERSION=VERSION))

def show_footer():
    """é¡¯ç¤ºé è…³"""
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: #888; margin-top: 2rem;">
        <small>
            ğŸ¨ <strong>AI åœ–åƒç”Ÿæˆå™¨ {VERSION}</strong> | 
            æ”¯æŒå¤šæ¨¡å‹å’Œå¤šä¾›æ‡‰å•† | 
            è®“å‰µæ„ç„¡é™å»¶ä¼¸ ğŸ¨
        </small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()